{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo de Quantization\n",
        "---\n",
        "\n",
        "En este ejemplo vamos a ver como cambiar la representación del modelo pasando los pesos y activaciones de FP32 a INT8. De esta forma, se obtinenen dos beneficios potenciales:\n",
        "\n",
        "\n",
        "1.   Reducimos el tamaño que ocupa el modelo ya que los pesos ocupan una cuarta parte (8 bits vs 32 bits por peso).\n",
        "2.   Si el dispositivo incorpora hardware para trabajar en 8 bits, se reduce el tiempo de ejecución. Sino, se mantiene el mismo que para 32 bits.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Instalar e importar las librerías necesarias\n",
        "\n",
        "En este ejemplo vamos a trabajar con Pytorch y los modelos de torchvision"
      ],
      "metadata": {
        "id": "7Ow23zCFEH4v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnsq0y32D6KW"
      },
      "outputs": [],
      "source": [
        "!pip3 install torch torchvision torchinfo numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet18, ResNet18_Weights, resnet50, ResNet50_Weights\n",
        "from torchinfo import summary\n",
        "import torch\n",
        "import torchvision\n",
        "import time\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "QcTQd3QwEM5j"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Definir el modelo\n",
        "\n",
        "Definimos el modelo, en este caso, usamos AlexNet pre-entrenada en ImageNet. Usamos esta red ya que es una red lineal sin conexiones residuales que producen problemas con la cuantización. Este tipo de problemas se pueden solventar cambiando algunas operaciones del modelo como se ve en este ejemplo para ResNet50 (https://github.com/zanvari/resnet50-quantization/blob/main/quantization-resnet50.ipynb)."
      ],
      "metadata": {
        "id": "jk6e0K0QGkOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.alexnet(weights=torchvision.models.AlexNet_Weights)\n",
        "preprocessing = torchvision.models.MobileNet_V3_Large_Weights.transforms\n",
        "summary(model, input_size=(1, 3, 224, 224))"
      ],
      "metadata": {
        "id": "3kPW7a7CGAIm"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Descargar la base de datos\n",
        "\n",
        "Vamos a trabajar con un subconjunto de ImageNet (conjunto t3 de entrenamiento). Nos lo descargamos y descomprimimos."
      ],
      "metadata": {
        "id": "Y2vqgUAaNulO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.ac.uma.es/~fcastro/files/imagenet.tar.gz\n",
        "!tar -xzf imagenet.tar.gz"
      ],
      "metadata": {
        "id": "YWJWbgX3Gvnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Definir un data loader\n",
        "\n",
        "Una vez descargados los datos, tenemos que crear un DataLoader de Pytorch para poder usarlos con nuestro modelo.\n"
      ],
      "metadata": {
        "id": "jEdYSwpwM2gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = torchvision.datasets.ImageFolder(root='./imagenet', transform=preprocessing)\n",
        "train_data_loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)"
      ],
      "metadata": {
        "id": "UN8vwaeNb6tU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Preparar la cuantización\n",
        "\n",
        "En este ejemplo vamos a usar una 'Quantization-Aware Training' para calibrar y transformar los pesos y activaciones de FP32 a INT8. De esta forma, los pesos se adaptan al nuevo rango de representación evitando problemas de cálculos que se salen fuera de rango y obteniendo un mejor accruacy que usando otras técnicas de cuantización como el 'Post-Training Quantization'.\n",
        "\n",
        "Para ello, tenemos que añadir unos adaptadores a la entrada y salida del modelo para convertir las entradas de FP32 a INT8 y nuestras salidas de INT8 a FP32. Tras esto, definimos la librería que realizará la cuantización y que depende del hardware en el que vamos a desplegar. Pytorch ofrece las siguientes opciones: https://pytorch.org/docs/stable/quantization.html#backend-hardware-support"
      ],
      "metadata": {
        "id": "5ihHzo0DO9SL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_fp32 = torch.nn.Sequential(torch.quantization.QuantStub(), model, torch.quantization.DeQuantStub())\n",
        "model_fp32.eval()\n",
        "model_fp32.qconfig = torch.quantization.get_default_qat_qconfig('qnnpack')\n",
        "model_fp32_prepared = torch.quantization.prepare_qat(model_fp32.train())\n",
        "summary(model_fp32_prepared, input_size=(1, 3, 224, 224))"
      ],
      "metadata": {
        "id": "qIX9cfdoLPF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Entrenamiento del modelo\n",
        "\n",
        "Realizamos unas épocas para calibrar los pesos del modelo y adaptarlo a la nueva representación. Para ello, usamos la base de datos que hemos descargado en el punto 3."
      ],
      "metadata": {
        "id": "SPFQTzjQQo7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 1\n",
        "opt = torch.optim.Adam(model_fp32_prepared.parameters(), lr=0.001)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "model_fp32_prepared.train()\n",
        "for epoch in range(n_epochs): # Entrenamos n epocas\n",
        "    train_running_loss = 0.0\n",
        "    train_running_correct = 0\n",
        "    counter = 0\n",
        "    time_start = time.time()\n",
        "    for inputs, labels in train_data_loader: # Obtenemos todos los batch de entrenamiento y los usamos para entrenar\n",
        "        opt.zero_grad()\n",
        "        outs = model_fp32_prepared(inputs)\n",
        "        loss = loss_fn(outs, labels)\n",
        "        train_running_loss += loss.item()\n",
        "        _, preds = torch.max(outs.data, 1)\n",
        "        train_running_correct += (preds == labels).sum().item()\n",
        "        counter = counter + 1\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    epoch_loss = train_running_loss / counter\n",
        "    epoch_acc = 100. * (train_running_correct / len(train_data_loader.dataset))\n",
        "    time_end = time.time() - time_start\n",
        "    print(f'** Summary for epoch {epoch}: '\n",
        "\t\tf'loss: {epoch_loss:#.3g}, acc: {epoch_acc:#.3g}]  '\n",
        "\t\tf'time: {time_end:.3f}s **')"
      ],
      "metadata": {
        "id": "QzVUI780Mx8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Exportar el modelo en INT8\n",
        "\n",
        "Una vez que hemos realizado el entrenamiento para pasar a INT8, simplemente limpiamos las capas auxiliares que añade Pytorch para realizar la calibración y exportamos el modelo a TorchScript para poder usarlo en un móvil."
      ],
      "metadata": {
        "id": "FxGT16QHQ6a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_fp32_prepared.eval()\n",
        "model_int8 = torch.quantization.convert(model_fp32_prepared, inplace=True)\n",
        "model_int8_script = torch.jit.script(model_int8) # Export to TorchScript\n",
        "summary(model_int8, input_size=(1, 3, 224, 224))\n",
        "torch.jit.save(model_int8_script, './model_int8.pt')"
      ],
      "metadata": {
        "id": "JTIDTKCLidSO"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Además, vamos a realizar una  inferencia de prueba para analizar el rendimiento del modelo inicial y el cuantizado."
      ],
      "metadata": {
        "id": "jcIiFXF7ROfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = torch.Tensor(np.random.rand(1,3,224,244)).float().cpu()\n",
        "print(image.shape)\n",
        "\n",
        "# FP32\n",
        "time_start = time.time()\n",
        "model(image)\n",
        "time_end = time.time() - time_start\n",
        "print(f'Execution time of the fp32 model: {time_end:.3f}s')\n",
        "\n",
        "# INT8\n",
        "time_start = time.time()\n",
        "model_int8(image)\n",
        "time_end = time.time() - time_start\n",
        "print(f'Execution time of the int8 model: {time_end:.3f}s')"
      ],
      "metadata": {
        "id": "CNE3EyU6JUx4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}